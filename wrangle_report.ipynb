{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle Report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Three sources of data with reference to a range of tweets are cleaned, tidied and merged into one single dataframe for future assessment. The data contains light-hearted user ratings of dogs, tweet interaction data and AI identification of breeds based on images.\n",
    "\n",
    "## Data Gathering\n",
    "\n",
    "1. Directly download the WeRateDogs Twitter archive data (twitter_archive_enhanced.csv)\n",
    "\n",
    "Imported the relevant libraries and read the csv into a pandas dataframe, df\n",
    "\n",
    "2. Use the Requests library to download the tweet image prediction (image_predictions.tsv)\n",
    "\n",
    "Imported the requests library and used teh get function to read the url into a response.\n",
    "Saved the response .tsv file.\n",
    "Read the .tsv into a pandas dataframe.\n",
    "\n",
    "3. Use the Tweepy library to query additional data via the Twitter API (tweet_json.txt)\n",
    "\n",
    "Imported the json library.\n",
    "Created a blank list, list_API\n",
    "Read in the tweet-json.txt file line by line into a dictionary\n",
    "Created a new pandas dataframe, df_API\n",
    "\n",
    "Note - Twitter would not allow me to access the API v2 on a 'Free' account subscription.\n",
    "\n",
    "## Assessing Data\n",
    "\n",
    "For each dataframe, used visual assessment including .head() and .tail() to become familar with data\n",
    "Use programmatic assessment .info() .desrcibe() to make note of the datatypes and number of entries per column, as well as max and min of certain values.\n",
    "    \n",
    "## Cleaning Data\n",
    "\n",
    "### Quality Issues\n",
    "\n",
    "Note: Three new dataframes with the suffix '_clean' are created to preserve raw data.\n",
    "\n",
    "1. Regarding 'df_clean', remove 181 retweets.\n",
    "\n",
    "A duplicate dataframe is created by taking the isnull values of the retweet status.\n",
    "    \n",
    "2. Regarding 'df_clean', remove rows that are using typo dog names. For the most part these appear to be spam (lobsters, humans, etc.), and names with lowercase first characters. This includes the following names; 'a', 'the', 'an', 'my'.\n",
    "\n",
    "Rows with Lowercase names are removed from the dataframe.\n",
    "\n",
    "3. Regarding 'df_clean', recreate the user rating from 'text' column and convert to float.\n",
    "\n",
    "Strings are extracted from the text colunn to create an accurate user rating into a new column and are converted into a float.\n",
    "\n",
    "4. Regarding 'df_clean', concatenate rating_numerator2 and rating_denominator2 into a single column 'score_ratio' and calculate a new value converting the ratio into a percentage for ease of analysis (readability and ranking), 'score_percentage'.\n",
    "\n",
    "A new column is creaated called 'score_percentage' as a float and is calculated using numerator2 and denominator2\n",
    "\n",
    "The numberator2 and denominator2 are converted into strings and concatenated using dataframe addition (+) separated by a '/' symbol into a new colunns 'score_ratio'.\n",
    "\n",
    "5. Regarding 'df_predictions_clean', keep rows where each AI recognizes the image as a dog.\n",
    "\n",
    "A query is performed to keep only a dataframe where p1_dog and p2_dog and p3_dog is True.\n",
    "\n",
    "6. Regarding 'df_API_clean', convert data type of column 'tweet_id' in dataframe 'df_API_clean' to int64.\n",
    "\n",
    "tweet_id is converted to integer to allow merge with other dataframes.\n",
    "\n",
    "### Tidiness issues\n",
    "\n",
    "1. Regarding 'df_clean', drop columns that aren't of interest in later analysis.\n",
    "\n",
    "Done to simplify the visual appearance of the final dataframe.\n",
    "\n",
    "2. Regarding 'df_clean', create a new column to account for dogs that aren't defined as either doggo, floofer, pupper and pupper. Once complete, melt the *doggo*, *floofer*, *pupper*, *puppo* and new 'Unknown' columns to a *dog_stage* column. Remove 'None' entries. Remove those that had multiple dog_stage definitions (remove duplicates).\n",
    "\n",
    "Carried out by merging column and then identifying mulitple values, removing 'None' entries. Had a originally tried .melt function but had issues with the multiple values.\n",
    "\n",
    "3. Merge 'df_predictions_clean' with 'df_clean', then merge 'df_API_clean' with 'df_clean'.\n",
    "\n",
    "Create a unified dataframe for ease of analysis.\n",
    "\n",
    "##  Storage\n",
    "\n",
    "A stored .csv version of df_clean is created as 'twitter_archive_master.csv'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
